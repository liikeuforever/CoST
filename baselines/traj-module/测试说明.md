# 轨迹压缩算法性能测试 - 使用指南

## 快速开始

### 1. 编译所有算法（首次使用）

```bash
./compile_all.sh
```

### 2. 运行测试

#### 快速测试（推荐，每个数据集10000点）

```bash
python3 run_quick_test.py
```

**运行时间**: 约 5 秒

#### 完整测试（全部100k点）

```bash
python3 run_tests.py
```

**运行时间**: 约 3 分钟

## 测试结果

所有测试结果保存在 `test_results/` 目录下。

### 主要输出文件

- **test_results_summary.txt** - 汇总报告（最重要）
- **{算法}_{数据集}_output.txt** - 每个测试的详细输出

## 最新测试结果摘要

**测试时间**: 2025-11-18  
**测试参数**: epsilon=50m  
**数据规模**: 每个数据集100,000个GPS点

### 算法性能对比（所有数据集平均）

| 算法 | 平均压缩比(%) | 压缩时间(us/点) | 解压时间(us/点) | 平均误差(m) |
|------|--------------|----------------|----------------|------------|
| **Dead_Reckoning** | 20.73 | 0.0327 | 0.0021 | 57.20 |
| **Douglas_Peucker** | 16.54 | 0.0108 | 0.0022 | 67.76 |
| **OPW_TR** | 31.25 | 0.3130 | 0.0017 | 13.13 |
| **SQUISH_E** | 24.28 | 0.1986 | 0.0021 | 15.18 |
| **VOLTCom** | 24.00 | 0.0680 | 0.0163 | 82.99 |

### 关键发现

1. **最优压缩比**: OPW_TR (31.25%)
2. **最快压缩速度**: Douglas_Peucker (0.0108 us/点)
3. **最快解压速度**: OPW_TR (0.0017 us/点)
4. **最低误差**: OPW_TR (13.13m)

### 各数据集详细结果

#### Geolife 数据集

| 算法 | 压缩比(%) | 压缩时间(us/点) | 解压时间(us/点) | 平均误差(m) |
|------|----------|----------------|----------------|-----------|
| Dead_Reckoning | 8.55 | 0.0325 | 0.0017 | 29.84 |
| Douglas_Peucker | 4.88 | 0.0093 | 0.0018 | 81.43 |
| **OPW_TR** | **10.39** | 0.3085 | **0.0016** | **13.98** |
| SQUISH_E | 10.76 | 0.3245 | 0.0018 | **9.51** |
| VOLTCom | 3.16 | 0.0625 | 0.0159 | 191.40 |

**特点**: 高精度轨迹，压缩难度较大

#### Trajectory 数据集

| 算法 | 压缩比(%) | 压缩时间(us/点) | 解压时间(us/点) | 平均误差(m) |
|------|----------|----------------|----------------|-----------|
| Dead_Reckoning | 21.39 | 0.0316 | 0.0020 | 31.46 |
| Douglas_Peucker | 20.90 | **0.0060** | 0.0021 | 33.48 |
| **OPW_TR** | **21.54** | 0.4562 | **0.0018** | 10.44 |
| SQUISH_E | 21.80 | 0.0696 | 0.0021 | **7.91** |
| VOLTCom | 16.09 | 0.0580 | 0.0146 | 44.58 |

**特点**: 均衡的压缩性能，所有算法表现稳定

#### WX_taxi 数据集

| 算法 | 压缩比(%) | 压缩时间(us/点) | 解压时间(us/点) | 平均误差(m) |
|------|----------|----------------|----------------|-----------|
| Dead_Reckoning | 32.24 | 0.0338 | 0.0027 | 110.31 |
| Douglas_Peucker | 23.84 | 0.0172 | 0.0026 | 88.36 |
| **OPW_TR** | **61.82** | 0.1744 | **0.0017** | **14.97** |
| SQUISH_E | 40.28 | 0.2016 | 0.0025 | 28.12 |
| VOLTCom | 52.76 | 0.0835 | 0.0183 | **12.98** |

**特点**: 出租车轨迹，规律性强，压缩效果最好

## 算法推荐

### 场景1: 需要最高压缩比
**推荐**: OPW_TR  
**理由**: 平均压缩比31.25%，在WX_taxi数据集上达到61.82%

### 场景2: 需要最快处理速度
**推荐**: Douglas_Peucker  
**理由**: 压缩速度最快(0.0108 us/点)，适合大规模实时处理

### 场景3: 需要最低误差
**推荐**: OPW_TR 或 SQUISH_E  
**理由**: 
- OPW_TR: 平均误差13.13m，整体最优
- SQUISH_E: 在Geolife和Trajectory上误差最低

### 场景4: 需要平衡性能
**推荐**: SQUISH_E  
**理由**: 压缩比24.28%，速度适中，误差较小(15.18m)

### 场景5: 对解压速度敏感
**推荐**: OPW_TR  
**理由**: 解压速度最快(0.0017 us/点)

## 自定义测试

### 修改测试参数

编辑 `run_tests.py`，修改以下参数：

```python
# 修改epsilon阈值（单位：米）
'params': lambda dataset, output: [dataset, '100.0', output, '-1']  # epsilon=100m

# 限制测试点数
'params': lambda dataset, output: [dataset, '50.0', output, '50000']  # 只测试50k点
```

### 添加新数据集

在 `run_tests.py` 中添加：

```python
DATASETS = [
    # ... 现有数据集 ...
    {
        'name': '我的数据集',
        'file': 'data_set/my_dataset.csv'
    }
]
```

### 单独测试某个算法

```bash
# 示例：测试 OPW_TR 算法
./build/OPW_TR data_set/Geolife_100k_with_id.csv 50.0 my_test.txt -1
```

## 文件说明

```
TrajectoryCompression/
├── compile_all.sh              # 编译脚本
├── run_tests.py                # 完整测试脚本
├── run_quick_test.py           # 快速测试脚本
├── README_TEST.md              # 详细技术文档
├── 测试说明.md                  # 本文档（中文快速指南）
├── build/                      # 编译输出目录
│   ├── Dead_Reckoning_Test
│   ├── Douglas_Peucker
│   ├── OPW_TR
│   ├── SQUISH_E
│   └── VOLTCom
├── test_results/               # 测试结果目录
│   ├── test_results_summary.txt  # 汇总报告
│   └── *.txt                   # 各算法详细输出
└── data_set/                   # 测试数据集
    ├── Geolife_100k_with_id.csv
    ├── Trajtory_100k_with_id.csv
    └── WX_taxi_100k_with_id.csv
```

## 技术支持

### 常见问题

**Q: 编译失败怎么办？**  
A: 确保已安装 g++ 编译器: `g++ --version`

**Q: 测试运行失败？**  
A: 检查数据集文件是否存在于 `data_set/` 目录

**Q: 如何只测试某几个算法？**  
A: 编辑测试脚本，注释掉不需要的算法配置

**Q: 测试时间太长？**  
A: 使用 `run_quick_test.py` 或修改 maxPoints 参数

### 性能优化建议

1. **大数据集测试**: 使用 `maxPoints` 参数限制点数
2. **编译优化**: 使用 `-O3` 优化级别（修改 `compile_all.sh`）
3. **并行测试**: 可以手动并行运行不同数据集的测试

## 引用和参考

详细的算法说明和论文引用请参考 `README_TEST.md`。

---

**最后更新**: 2025-11-18  
**测试环境**: macOS Darwin 24.5.0, g++ compiler


